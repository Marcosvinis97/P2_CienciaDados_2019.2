{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Cicero Tiago Carneiro Valentim\n",
    "\n",
    "Nome: Luiz Felipe Lazzaron\n",
    "\n",
    "Nome: Marcos Vinícius da Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "No presente trabalho, visa-se selecionar tweets relevantes para a classificação de postagens que possuem sinais de depressão por parte de seus autores. Nesse contexto, os integrantes dividiram os tweets em três categorias:\n",
    "\n",
    "1. Irrelavantes ou Neutros. Tweets que não indicam quaisquer indício de depressão;\n",
    "2. Relevantes. Tweets que possuem relevância na análise de indicação de depressão;\n",
    "3. Possuem interesse no assunto. Tweets que não demonstram doença mental, mas indicam um interresse no tema e na prevenção de suicídio.\n",
    "\n",
    "Desse modo, com tal classificação, pode-se desenvolver um marketing específico para os públicos 2 e 3; para os relevantes, pode-se oferecer auxílio e suporte psicológico; para aqueles que possuem interesse no tema \"depressão\", pode-se direcionar materiais que ensinem a como lidar com pessoas com depressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@MarcosV96118169***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @MarcosV96118169\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Depressão'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "# i = 1\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "#     new_msg = { 'User Name': msg.user.name,\n",
    "#                 'Tweet Created At': msg.created_at,\n",
    "#                 'Tweet Text': msg.full_text.lower(),\n",
    "#                 'User Location': msg.user.location,\n",
    "#                 'Phone Type': msg.source,\n",
    "#                 'Favorite Count': msg.favorite_count,\n",
    "#                 'Retweets':msg.retweet_count\n",
    "#                 }\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um Dataframe com a Base de Dados\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# pd.DataFrame(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "planilha_treinamento = pd.read_excel('depressao.xlsx', \"Treinamento\")\n",
    "planilha_teste = pd.read_excel('depressao.xlsx', \"Teste\")\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Montando o Classificador Naive-Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, iremos trabalhar com o dataframe treinamento, criando três banco de dados:\n",
    "    \n",
    "- **Grupo 1 - Irrelevantes/Neutros**: *group_1*\n",
    "- **Grupo 2 - Relevantes**: *group_2*\n",
    "- **Grupo 3 - Interesse no Assunto**: *group_3*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = planilha_treinamento[planilha_treinamento[\"Relevância\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_2 = planilha_treinamento[planilha_treinamento[\"Relevância\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_3 = planilha_treinamento[planilha_treinamento[\"Relevância\"] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group_1,group_2,group_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando bibliotecas necessárias para análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "#Bibliotecas para a Identificação de Emojis\n",
    "!pip install emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import emoji\n",
    "import re \n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Limpeza de um Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe um texto normal e devolve uma lista de split\n",
    "def space_cleaning(text):\n",
    "    punctuation = '[!\\-.:?;,''\"@/]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    split_emoji = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    split_whitespace = [substr.split() for substr in split_emoji]\n",
    "    split = functools.reduce(operator.concat,split_whitespace)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe um lista split e devolve uma lista split sem http ou https\n",
    "def remove_http(lista_de_listas):\n",
    "    lista = lista_de_listas\n",
    "    for i in range(len(lista)):\n",
    "        for j in range(len(lista[i])):\n",
    "            if 'HTTP' in lista[i][j].capitalize():\n",
    "                lista[i][j] = \"http\"\n",
    "    \n",
    "    for i in range(len(lista)):\n",
    "        while lista[i].count(\"http\") != 0:\n",
    "            lista[i].remove(\"http\")\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-967d4db2a760>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Estou testando essa função https://facebook.com @marcelinhoparaiba\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_http\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-55bbee109978>\u001b[0m in \u001b[0;36mremove_http\u001b[1;34m(lista_de_listas)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlista\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mlista\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "a = \"Estou testando essa função https://facebook.com @marcelinhoparaiba\"\n",
    "b = space_cleaning(a)\n",
    "c = remove_http(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando os Dados da Base de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups_tweet = []\n",
    "# for group in groups:\n",
    "#     tweet_group = group['Tweet Text'] \n",
    "#     tweet_group = str(tweet_group)\n",
    "#     tweet_group = space_cleaning(tweet_group)\n",
    "#     groups_tweet.append(tweet_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamento_do_grupo(grupo):\n",
    "    total = []\n",
    "    for tweet in grupo[\"Tweet Text\"]:\n",
    "        tweet_splited = space_cleaning(tweet)\n",
    "       # tweet_splited = remove_http(tweet_splited)\n",
    "        total.append(tweet_splited)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_tweet = [tratamento_do_grupo(groups[0]),tratamento_do_grupo(groups[1]),tratamento_do_grupo(groups[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes e Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de Elementos De todos os grupos sem repetição\n",
    "total_words = []\n",
    "def lista_sem_repeticao(LISTA,lista):\n",
    "    resposta = LISTA\n",
    "    for tweet in lista:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in resposta:\n",
    "                resposta.append(palavra)\n",
    "    return resposta\n",
    "lista_sem_repeticao(total_words,groups_tweet[0])\n",
    "lista_sem_repeticao(total_words,groups_tweet[1])\n",
    "lista_sem_repeticao(total_words,groups_tweet[2])\n",
    "N =len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2970"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de Laplace\n",
    "def laplace(num_vezes_no_grupo, num_elementos_do_grupo, num_elementos_sem_repeticao):\n",
    "    probabilidade = (num_vezes_no_grupo + 1 ) / ( num_elementos_do_grupo + num_elementos_sem_repeticao)\n",
    "    return probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de vezes que a palavra aparece no grupo\n",
    "def numero_de_vezes(palavra_analisada,grupo):\n",
    "    n = 0\n",
    "    for tweet in grupo:\n",
    "        for palavra in tweet:\n",
    "            if palavra ==  palavra_analisada:\n",
    "                n +=1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numero_de_vezes(\"depressão\",groups_tweet[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probabilidade para cada palavra\n",
    "resultados = []\n",
    "for group in groups_tweet:\n",
    "    dictionary= {}\n",
    "    for tweet in group:\n",
    "        for word in tweet:\n",
    "            probabilidade = laplace(numero_de_vezes(word,group),len(group),N)\n",
    "            dictionary[word] = probabilidade\n",
    "    resultado = pd.Series(dictionary)\n",
    "    resultados.append(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de Palavras em Cada uma dos Grupos\n",
    "def conta_palavras(grupo):\n",
    "    n = 0\n",
    "    for tweet in grupo:\n",
    "        n += len(tweet)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = conta_palavras(groups_tweet[0])\n",
    "N_2 = conta_palavras(groups_tweet[1])\n",
    "N_3 = conta_palavras(groups_tweet[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance na Planilha Testes\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = planilha_teste[\"Tweet Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_tweet(tweet):\n",
    "    tweet_limpo = space_cleaning(str(tweet))\n",
    "    return tweet_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_tweet = []\n",
    "for tweet in teste:\n",
    "    teste_tweet.append(limpeza_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_teste = pd.Series(teste_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultados[0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de Análise\n",
    "\n",
    "Como os resultados estão muito pequenos, usou-se a função do logarítmo neperiano, ln(x), para os valores ficarem com números mais adequados para o Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de Análise de Frase\n",
    "def analisa_frase(frase):\n",
    "    condicional_grupo1 = 1\n",
    "    condicional_grupo2 = 1\n",
    "    condicional_grupo3 = 1\n",
    "    lista = [condicional_grupo1, condicional_grupo2,condicional_grupo3]\n",
    "    \n",
    "    for palavra in frase:\n",
    "        if (palavra not in resultados[0].index):\n",
    "            condicional_grupo1 *= laplace(0,N_1,N)\n",
    "        else: \n",
    "            condicional_grupo1 *= resultados[0][palavra]\n",
    "            \n",
    "    for palavra in frase:\n",
    "        if (palavra not in resultados[1].index):\n",
    "            condicional_grupo2 *= laplace(0,N_1,N) \n",
    "        else:\n",
    "            condicional_grupo2 *= resultados[1][palavra]\n",
    "            \n",
    "    for palavra in frase:\n",
    "        if (palavra not in resultados[2].index):\n",
    "            condicional_grupo3 *= laplace(0,N_1,N) \n",
    "        else:\n",
    "            condicional_grupo3 *= resultados[2][palavra]\n",
    "            \n",
    "    return [condicional_grupo1,condicional_grupo2,condicional_grupo3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1116983151648638e-60, 4.458025834425154e-61, 1.3518821708300341e-62]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analisa_frase(\"Gostei muito de você\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifica_valor_maximo(lista_de_resultados):\n",
    "    if lista_de_resultados[0] == max(lista_de_resultados):\n",
    "        return 1\n",
    "    elif lista_de_resultados[1] == max(lista_de_resultados):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultado(n):\n",
    "    return identifica_valor_maximo(analisa_frase(limpeza_tweet(teste[n])))\n",
    "estimativa = []\n",
    "for k in range(0,len(teste)):\n",
    "    estimativa.append(resultado(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "planilha_teste[\"Relevância_Estimada\"] = estimativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acertos = 0\n",
    "for n in planilha_teste.index:\n",
    "    if planilha_teste[\"Relevância_Prevista\"][n] == planilha_teste[\"Relevância_Estimada\"][n]:\n",
    "        Acertos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.492205\n",
       "2.0    0.285078\n",
       "3.0    0.222717\n",
       "Name: Relevância, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_treinamento[\"Relevância\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.536667\n",
       "3    0.236667\n",
       "2    0.223333\n",
       "0    0.003333\n",
       "Name: Relevância_Prevista, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste[\"Relevância_Prevista\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.93\n",
       "2    0.05\n",
       "3    0.02\n",
       "Name: Relevância_Estimada, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste[\"Relevância_Estimada\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acertos/len(planilha_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
